
The project focused on developing a robust emotion recognition system using a Convolutional Neural Network (CNN) built with TensorFlow and Keras. The dataset, comprising 981 images across seven emotion classes (anger, contempt, disgust, fear, happy, sadness, surprise), was preprocessed and augmented for model training. The CNN architecture consisted of several convolutional layers followed by max-pooling layers, ultimately culminating in two fully connected layers for classification. The model underwent training with 50 epochs, achieving a high accuracy of approximately 99.48% on the test data. The training and validation accuracy and loss were visualized to monitor the model's performance, showcasing a steady improvement in accuracy and reduction in loss over epochs. Utilizing early stopping to prevent overfitting, the model was fine-tuned with an adaptive learning rate schedule. The resultant model accurately predicted emotions from sampled images, demonstrating its proficiency in recognizing emotions from facial expressions.
